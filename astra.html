<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASTRA - AI Assistant</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #ff1b4d; /* Opera GX red */
            --secondary: #00ebc7; /* Opera GX teal */
            --accent: #7700ff; /* Opera GX purple */
            --bg-dark: #0d0d17;
            --text-glow: 0 0 10px currentColor;
        }

        body {
            margin: 0;
            padding: 0;
            background-color: var(--bg-dark);
            overflow: hidden;
            font-family: 'Orbitron', sans-serif;
            color: var(--primary);
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            background-image: 
                radial-gradient(circle at 20% 30%, rgba(119, 0, 255, 0.15) 0%, transparent 25%),
                radial-gradient(circle at 80% 70%, rgba(255, 27, 77, 0.15) 0%, transparent 25%),
                linear-gradient(to bottom, transparent 95%, rgba(255, 27, 77, 0.05) 100%);
        }

        .hologram-container {
            position: relative;
            width: 90vmin;
            height: 90vmin;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .hologram-circle {
            position: absolute;
            border-radius: 50%;
            border: 1px solid;
            animation-timing-function: linear;
            animation-iteration-count: infinite;
            mix-blend-mode: screen;
            filter: drop-shadow(var(--text-glow));
        }

        .circle-1 {
            width: 100%;
            height: 100%;
            border-color: var(--primary);
            animation: rotate 60s infinite, pulse-opacity 8s infinite;
            box-shadow: 0 0 40px rgba(255, 27, 77, 0.4);
        }

        .circle-2 {
            width: 80%;
            height: 80%;
            border-color: var(--secondary);
            animation: rotate-reverse 45s infinite, pulse-opacity 12s infinite 2s;
            box-shadow: 0 0 40px rgba(0, 235, 199, 0.4);
        }

        .circle-3 {
            width: 60%;
            height: 60%;
            border-color: var(--accent);
            animation: rotate 30s infinite, pulse-opacity 15s infinite 4s;
            box-shadow: 0 0 40px rgba(119, 0, 255, 0.4);
        }

        .hologram-core {
            position: relative;
            width: 40%;
            height: 40%;
            border-radius: 50%;
            background: radial-gradient(circle, rgba(255, 27, 77, 0.2) 0%, transparent 70%);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            text-align: center;
            z-index: 10;
            transition: all 0.3s ease;
        }

        .core-text {
            font-size: 2rem;
            margin-bottom: 1rem;
            text-shadow: var(--text-glow);
            opacity: 0.9;
            animation: pulse-text 3s infinite;
            font-weight: 700;
        }

        .core-response {
            font-size: 0.9rem;
            max-width: 80%;
            opacity: 0;
            transition: opacity 0.3s;
            text-shadow: 0 0 5px var(--secondary);
            line-height: 1.4;
        }

        .response-visible {
            opacity: 0.9;
        }

        .voice-active .hologram-core {
            background: radial-gradient(circle, rgba(255, 27, 77, 0.5) 0%, transparent 70%);
            box-shadow: 0 0 60px rgba(255, 27, 77, 0.3);
        }

        .status {
            position: absolute;
            top: 5%;
            font-size: 0.9rem;
            text-transform: uppercase;
            letter-spacing: 3px;
            opacity: 0.7;
            text-shadow: var(--text-glow);
            transition: all 0.3s;
        }

        .status-active {
            color: var(--secondary);
            opacity: 1;
        }

        .mic-btn {
            position: absolute;
            bottom: 10%;
            background: transparent;
            border: 1px solid var(--primary);
            color: var(--primary);
            padding: 1rem 2rem;
            border-radius: 50px;
            font-family: 'Orbitron', sans-serif;
            cursor: pointer;
            transition: all 0.3s;
            z-index: 20;
            opacity: 0.8;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 700;
            text-shadow: var(--text-glow);
        }

        .mic-btn:hover {
            opacity: 1;
            background: rgba(255, 27, 77, 0.2);
            box-shadow: 0 0 20px rgba(255, 27, 77, 0.4);
        }

        .mic-btn.active {
            border-color: var(--secondary);
            color: var(--secondary);
            box-shadow: 0 0 20px rgba(0, 235, 199, 0.4);
        }

        .permission-error {
            color: #ff1b4d;
            position: absolute;
            bottom: 20%;
            width: 100%;
            text-align: center;
            font-size: 0.8rem;
            display: none;
            text-shadow: var(--text-glow);
            animation: shake 0.5s;
        }

        .confidence-meter {
            position: absolute;
            bottom: 25%;
            width: 60%;
            height: 2px;
            background: rgba(255, 255, 255, 0.1);
            display: none;
        }

        .confidence-level {
            height: 100%;
            background: linear-gradient(to right, var(--primary), var(--secondary));
            transition: width 0.3s;
        }

        @keyframes rotate {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @keyframes rotate-reverse {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(-360deg); }
        }

        @keyframes pulse-opacity {
            0%, 100% { opacity: 0.4; }
            50% { opacity: 0.9; }
        }

        @keyframes pulse-text {
            0%, 100% { opacity: 0.8; }
            50% { opacity: 1; }
        }

        @keyframes shake {
            0%, 100% { transform: translateX(0); }
            20%, 60% { transform: translateX(-5px); }
            40%, 80% { transform: translateX(5px); }
        }

        /* Loading animation */
        .loading-dots {
            display: inline-flex;
            align-items: center;
            justify-content: center;
        }

        .loading-dots span {
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background-color: var(--secondary);
            margin: 0 3px;
            opacity: 0.4;
        }

        .loading-dots span:nth-child(1) {
            animation: bounce 1s infinite;
        }
        .loading-dots span:nth-child(2) {
            animation: bounce 1s infinite 0.2s;
        }
        .loading-dots span:nth-child(3) {
            animation: bounce 1s infinite 0.4s;
        }

        @keyframes bounce {
            0%, 100% { transform: translateY(0); opacity: 0.4; }
            50% { transform: translateY(-5px); opacity: 1; }
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            .hologram-container {
                width: 95vmin;
                height: 95vmin;
            }
            
            .core-text {
                font-size: 1.5rem;
            }
            
            .mic-btn {
                padding: 0.8rem 1.5rem;
                font-size: 0.8rem;
            }
        }
    </style>
</head>
<body>
    <div class="hologram-container" id="container">
        <div class="status" id="status">SYSTEM STANDBY</div>
        
        <div class="hologram-circle circle-1"></div>
        <div class="hologram-circle circle-2"></div>
        <div class="hologram-circle circle-3"></div>
        
        <div class="hologram-core" id="core">
            <div class="core-text">ASTRA</div>
            <div class="core-response" id="response"></div>
        </div>
        
        <div class="confidence-meter" id="confidence-meter">
            <div class="confidence-level" id="confidence-level"></div>
        </div>
        
        <div class="permission-error" id="permission-error">
            Microphone permission denied. Please allow microphone access.
        </div>
        
        <button class="mic-btn" id="mic-btn">ENABLE MICROPHONE</button>
    </div>

    <script>
        // Using Hugging Face's free inference API with a reliable model
        const HF_API_KEY = "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";
        const MODEL_NAME = "mistralai/Mistral-7B-Instruct-v0.1"; // Fast and capable model
        
        // DOM Elements
        const container = document.getElementById('container');
        const core = document.getElementById('core');
        const responseEl = document.getElementById('response');
        const statusEl = document.getElementById('status');
        const micBtn = document.getElementById('mic-btn');
        const permissionError = document.getElementById('permission-error');
        const confidenceMeter = document.getElementById('confidence-meter');
        const confidenceLevel = document.getElementById('confidence-level');
        
        // Check if speech recognition is available
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
            responseEl.textContent = "Speech recognition not supported in your browser";
            responseEl.classList.add('response-visible');
            micBtn.disabled = true;
            micBtn.textContent = "UNSUPPORTED";
            micBtn.style.opacity = "0.5";
        }
        
        // Enhanced Speech Recognition
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = true;
        recognition.lang = 'en-US';
        recognition.maxAlternatives = 3; // Get multiple alternatives for better accuracy
        
        // Speech Synthesis
        const synth = window.speechSynthesis;
        
        // State
        let isActive = false;
        const wakeWord = "astra";
        let permissionGranted = false;
        let silenceTimer;
        const SILENCE_TIMEOUT = 5000; // 5 seconds of silence
        let processingRequest = false;
        
        // Functions
        function updateStatus(text, isActiveState = false) {
            statusEl.textContent = text;
            if (isActiveState) {
                statusEl.classList.add('status-active');
            } else {
                statusEl.classList.remove('status-active');
            }
        }
        
        function updateResponse(text) {
            responseEl.textContent = text;
            responseEl.classList.add('response-visible');
        }
        
        function clearResponse() {
            responseEl.textContent = '';
            responseEl.classList.remove('response-visible');
        }
        
        function showPermissionError() {
            permissionError.style.display = 'block';
            setTimeout(() => {
                permissionError.style.display = 'none';
            }, 5000);
        }
        
        function showConfidenceMeter(confidence) {
            confidenceMeter.style.display = 'block';
            confidenceLevel.style.width = `${confidence * 100}%`;
            setTimeout(() => {
                confidenceMeter.style.display = 'none';
            }, 2000);
        }
        
        function showLoadingIndicator() {
            responseEl.innerHTML = '<div class="loading-dots"><span></span><span></span><span></span></div>';
            responseEl.classList.add('response-visible');
        }
        
        function speak(text) {
            if (synth.speaking) synth.cancel();
            
            // Process text to make it more concise
            let processedText = text.trim();
            
            // Remove unnecessary formalities and shorten
            processedText = processedText.replace(/^(Certainly! |Of course! |Absolutely! |I'd be happy to help! |Here you go: )/i, '');
            processedText = processedText.replace(/(Let me know if you need anything else\.|Is there anything else I can help with\?|Please let me know if you have any other questions\.)$/i, '');
            
            // Limit to 50 words unless it's a complex answer
            const words = processedText.split(' ');
            if (words.length > 50 && !processedText.includes('?')) {
                processedText = words.slice(0, 50).join(' ') + '...';
            }
            
            const utterance = new SpeechSynthesisUtterance(processedText);
            
            // Set female voice with optimal settings
            const voices = synth.getVoices();
            const preferredVoices = [
                'Microsoft Zira Desktop', // Windows
                'Google UK English Female', // Chrome
                'Samantha', // Mac
                'Karen', // Mac
                'Microsoft Hazel Desktop', // Windows
                'Google US English Female' // Chrome
            ];
            
            let voice = voices.find(v => preferredVoices.includes(v.name)) || 
                       voices.find(v => v.lang.includes('en') && v.name.includes('Female')) || 
                       voices.find(v => v.default);
            
            if (voice) utterance.voice = voice;
            
            // Optimal speech settings
            utterance.rate = 0.95;
            utterance.pitch = 1.1;
            utterance.volume = 1;
            
            container.classList.add('voice-active');
            utterance.onend = () => {
                container.classList.remove('voice-active');
                // Restart recognition after speaking is done
                if (isActive && !processingRequest) {
                    setTimeout(() => recognition.start(), 800);
                }
            };
            
            synth.speak(utterance);
        }
        
        async function queryAI(prompt) {
            processingRequest = true;
            updateStatus("PROCESSING", true);
            showLoadingIndicator();
            
            try {
                const response = await fetch(
                    `https://api-inference.huggingface.co/models/${MODEL_NAME}`,
                    {
                        method: "POST",
                        headers: {
                            "Authorization": `Bearer ${HF_API_KEY}`,
                            "Content-Type": "application/json"
                        },
                        body: JSON.stringify({
                            inputs: `<|system|>
You are ASTRA, an advanced AI assistant with a friendly but efficient personality. Respond concisely (30-50 words max) in a casual but professional tone. Skip formalities unless specifically asked for details. Be helpful and to the point.

Current query: ${prompt}</s>
<|assistant|>`,
                            parameters: {
                                max_new_tokens: 100,
                                temperature: 0.7,
                                top_p: 0.9,
                                repetition_penalty: 1.2,
                                return_full_text: false
                            }
                        })
                    }
                );
                
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error || "API error");
                }
                
                const result = await response.json();
                return result[0].generated_text.trim();
            } catch (error) {
                console.error("AI Error:", error);
                return "Sorry, I'm having trouble processing that. Could you try again?";
            } finally {
                processingRequest = false;
            }
        }
        
        // Event Handlers
        recognition.onstart = () => {
            updateStatus("LISTENING", true);
            container.classList.add('voice-active');
            permissionGranted = true;
            micBtn.textContent = "LISTENING...";
            micBtn.classList.add('active');
            clearResponse();
            
            // Start silence timer
            clearTimeout(silenceTimer);
            silenceTimer = setTimeout(() => {
                if (isActive && !processingRequest) {
                    recognition.stop();
                    updateStatus("TIMEOUT", false);
                    speak("I didn't hear anything. Going back to standby.");
                    isActive = false;
                    micBtn.textContent = "ENABLE MICROPHONE";
                    micBtn.classList.remove('active');
                }
            }, SILENCE_TIMEOUT);
        };
        
        recognition.onend = () => {
            container.classList.remove('voice-active');
            if (!processingRequest) {
                updateStatus(isActive ? "AWAITING COMMAND" : "STANDBY", isActive);
                if (isActive) {
                    micBtn.textContent = "READY";
                } else {
                    micBtn.textContent = "ENABLE MICROPHONE";
                    micBtn.classList.remove('active');
                }
            }
            clearTimeout(silenceTimer);
        };
        
        recognition.onresult = async (event) => {
            clearTimeout(silenceTimer); // Reset silence timer
            
            const results = event.results;
            const lastResult = results[results.length - 1];
            
            if (lastResult.isFinal) {
                // Get the most confident alternative
                let bestAlternative = lastResult[0];
                for (let i = 1; i < lastResult.length; i++) {
                    if (lastResult[i].confidence > bestAlternative.confidence) {
                        bestAlternative = lastResult[i];
                    }
                }
                
                const transcript = bestAlternative.transcript.toLowerCase().trim();
                const confidence = bestAlternative.confidence;
                
                // Show confidence level
                showConfidenceMeter(confidence);
                
                // Ignore low-confidence results (likely background noise)
                if (confidence < 0.5) {
                    console.log("Ignoring low-confidence result:", transcript, confidence);
                    return;
                }
                
                console.log("Heard:", transcript, "Confidence:", confidence);
                
                if (!isActive) {
                    if (transcript.includes(wakeWord)) {
                        isActive = true;
                        speak("I'm listening. What can I do for you?");
                        updateStatus("AWAITING COMMAND", true);
                        micBtn.textContent = "READY";
                    }
                } else {
                    if (transcript.includes("deactivate") || transcript.includes("standby")) {
                        isActive = false;
                        speak("Going to standby");
                        updateStatus("STANDBY", false);
                        return;
                    }
                    
                    // Only process if we have reasonable confidence
                    if (confidence >= 0.6) {
                        const aiResponse = await queryAI(transcript);
                        updateResponse(aiResponse);
                        speak(aiResponse);
                    } else {
                        console.log("Ignoring due to low confidence:", transcript);
                        speak("Sorry, I didn't catch that. Could you repeat?");
                    }
                }
            }
        };
        
        recognition.onerror = (event) => {
            console.error("Speech error:", event.error);
            
            if (event.error === 'not-allowed') {
                showPermissionError();
                updateStatus("PERMISSION DENIED", false);
                micBtn.textContent = "ENABLE MICROPHONE";
                micBtn.classList.remove('active');
                permissionGranted = false;
            } else if (event.error === 'no-speech') {
                // Just restart if no speech detected
                if (isActive && !processingRequest) {
                    setTimeout(() => recognition.start(), 500);
                }
            } else {
                updateStatus("ERROR: " + event.error, false);
                speak("I encountered an error. Please try again.");
            }
            
            container.classList.remove('voice-active');
            clearTimeout(silenceTimer);
        };
        
        micBtn.addEventListener('click', async () => {
            try {
                // First request microphone permission
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { 
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                        sampleRate: 44100
                    } 
                });
                
                // If we get here, permission was granted
                stream.getTracks().forEach(track => track.stop());
                
                // Now start speech recognition
                updateStatus("INITIALIZING", true);
                micBtn.textContent = "INITIALIZING...";
                recognition.start();
                
            } catch (error) {
                console.error("Microphone permission error:", error);
                showPermissionError();
                updateStatus("PERMISSION DENIED", false);
                micBtn.textContent = "ENABLE MICROPHONE";
                micBtn.classList.remove('active');
            }
        });
        
        // Initialization
        updateStatus("SYSTEM STANDBY", false);
        
        // Check if we already have permission
        if (navigator.permissions && navigator.permissions.query) {
            navigator.permissions.query({ name: 'microphone' }).then(permissionStatus => {
                if (permissionStatus.state === 'granted') {
                    micBtn.click();
                }
                permissionStatus.onchange = () => {
                    if (permissionStatus.state === 'granted') {
                        micBtn.click();
                    }
                };
            }).catch(error => {
                console.log("Permissions API not fully supported");
            });
        }

        // Load voices when they become available
        function loadVoices() {
            return new Promise(resolve => {
                const voices = synth.getVoices();
                if (voices.length > 0) {
                    resolve(voices);
                } else {
                    synth.onvoiceschanged = () => {
                        resolve(synth.getVoices());
                    };
                }
            });
        }
        
        // Initialize voices
        loadVoices().then(voices => {
            console.log("Available voices:", voices);
        });
    </script>
</body>
</html>
