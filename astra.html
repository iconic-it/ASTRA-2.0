<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASTRA</title>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            background-color: #121212;
            color: #e0e0e0;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        #status {
            color: #4CAF50;
            font-weight: bold;
            margin-bottom: 20px;
        }
        #output {
            background-color: #1e1e1e;
            border-radius: 8px;
            padding: 15px;
            min-height: 100px;
            margin-bottom: 20px;
            border-left: 4px solid #4CAF50;
        }
        button {
            background-color: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            text-align: center;
            text-decoration: none;
            display: inline-block;
            font-size: 16px;
            margin: 4px 2px;
            cursor: pointer;
            border-radius: 4px;
            transition: all 0.3s;
        }
        button:hover {
            background-color: #45a049;
        }
        #jarvis-btn {
            background-color: #2196F3;
        }
        #jarvis-btn:hover {
            background-color: #0b7dda;
        }
        .container {
            text-align: center;
        }
        h1 {
            color: #2196F3;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>JARVIS-like AI Assistant</h1>
        <div id="status">Status: Ready</div>
        <button id="start-btn">Start Listening</button>
        <button id="jarvis-btn">Activate JARVIS</button>
        <div id="output">Responses will appear here...</div>
    </div>

    <script>
        // Configuration - Replace with your Hugging Face API key
        const HF_API_KEY = "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";
        const MODEL_NAME = "deepseek-ai/deepseek-llm-67b"; // You can change this to any chat model
        
        // DOM elements
        const startBtn = document.getElementById('start-btn');
        const jarvisBtn = document.getElementById('jarvis-btn');
        const outputDiv = document.getElementById('output');
        const statusDiv = document.getElementById('status');
        
        // Speech recognition and synthesis
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';
        
        const synth = window.speechSynthesis;
        
        // State variables
        let isJarvisActive = false;
        let wakeWord = "astra";
        
        // Initialize
        function updateStatus(message) {
            statusDiv.textContent = `Status: ${message}`;
        }
        
        function appendToOutput(text, isUser = false) {
            const prefix = isUser ? '<span style="color:#2196F3">You:</span> ' : '<span style="color:#4CAF50">JARVIS:</span> ';
            outputDiv.innerHTML += `<p>${prefix}${text}</p>`;
            outputDiv.scrollTop = outputDiv.scrollHeight;
        }
        
        function speak(text) {
            if (synth.speaking) {
                synth.cancel();
            }
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 1.0;
            utterance.pitch = 0.9;
            utterance.voice = synth.getVoices().find(voice => voice.name.includes('Google US English') || voice.default);
            
            synth.speak(utterance);
        }
        
        // Hugging Face API call
        async function queryHuggingFace(prompt) {
            updateStatus("Thinking...");
            
            try {
                const response = await fetch(
                    `https://api-inference.huggingface.co/models/${MODEL_NAME}`,
                    {
                        method: "POST",
                        headers: {
                            "Authorization": `Bearer ${HF_API_KEY}`,
                            "Content-Type": "application/json"
                        },
                        body: JSON.stringify({
                            inputs: prompt,
                            parameters: {
                                max_new_tokens: 200,
                                temperature: 0.7,
                                return_full_text: false
                            }
                        })
                    }
                );
                
                if (!response.ok) {
                    throw new Error(`API request failed with status ${response.status}`);
                }
                
                const result = await response.json();
                return result[0].generated_text;
            } catch (error) {
                console.error("Error calling the API:", error);
                return "I encountered an error processing your request. Please try again.";
            }
        }
        
        // Voice recognition handlers
        recognition.onstart = () => {
            updateStatus("Listening...");
        };
        
        recognition.onend = () => {
            if (!isJarvisActive) {
                updateStatus("Ready (say 'ASTRA' to activate)");
            } else {
                updateStatus("ASTRA is active - Speak your command");
            }
        };
        
        recognition.onresult = async (event) => {
            const transcript = event.results[0][0].transcript.toLowerCase().trim();
            
            if (!isJarvisActive) {
                if (transcript.includes(wakeWord)) {
                    isJarvisActive = true;
                    appendToOutput(transcript, true);
                    speak("Hello user, how may I assist you?");
                    updateStatus("ASTRA Active - Listening for command");
                    recognition.start(); // Continue listening
                }
            } else {
                appendToOutput(transcript, true);
                
                if (transcript.includes("deactivate") || transcript.includes("sleep")) {
                    isJarvisActive = false;
                    speak("Going to sleep. Say 'ASTRA' to wake me up.");
                    updateStatus("Ready (say 'ASTRA' to activate)");
                    return;
                }
                
                // Process the command
                const response = await queryHuggingFace(
                    `You are ASTRA, an advanced AI assistant. Respond to the following query in a concise, helpful manner: ${transcript}`
                );
                
                appendToOutput(response);
                speak(response);
                
                // Continue listening for more commands
                recognition.start();
            }
        };
        
        recognition.onerror = (event) => {
            updateStatus(`Error: ${event.error}`);
            console.error("Speech recognition error", event);
        };
        
        // Button event listeners
        startBtn.addEventListener('click', () => {
            recognition.start();
            updateStatus("Listening...");
        });
        
        jarvisBtn.addEventListener('click', () => {
            isJarvisActive = true;
            updateStatus("ASTRA Active - Listening for command");
            speak("At your service, sir. How may I assist you?");
            recognition.start();
        });
        
        // Initial setup
        updateStatus("Ready (say 'ASTRA' to activate)");
        appendToOutput("System initialized. Say 'ASTRA' or click the button to activate.", false);
    </script>
</body>
</html>
